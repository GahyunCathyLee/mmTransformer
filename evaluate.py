import os
import csv
import pickle
import numpy as np
import h5py
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm
import argparse
from torch.amp import autocast
import time
from pathlib import Path

from lib.utils.utilities import load_config_data
from lib.models.mmTransformer import mmTrans
from lib.models.TF_version.stacked_transformer import STF

EXTRA_FEATURE_MAP = {
    'baseline': [0, 1],              
    'exp1': [0, 1, 6, 7],                  
    'exp2': [0, 1, 4, 5, 6, 7, 8],               
    'exp3': [0, 1, 2, 3, 4, 5, 8],               
    'exp4': [0, 1, 2, 3, 4, 5, 6, 7, 8],   
    'exp5': [0, 1, 6, 7, 8],
    'exp6': [6, 7],
    'exp7': [4, 5, 6, 7, 8],
    'exp8': [0, 1, 6, 8],
    'exp9': [0, 1, 8]            
}

# ==============================================================================
# 1. Dataset (train.pyì™€ ë™ì¼ êµ¬ì¡°)
# ==============================================================================
class HighDDataset(Dataset):
    def __init__(self, data_path, map_path):
        self.h5_path = data_path
        
        with open(map_path, 'rb') as f:
            map_info = pickle.load(f)
            self.map_data = map_info['Map']
        
        print(f"[{data_path}] RAMì— ë°ì´í„°ë¥¼ ì˜¬ë¦¬ëŠ” ì¤‘...")
        with h5py.File(self.h5_path, 'r') as f:
            self.length = len(f['HISTORY'])
            
            self.hist = torch.from_numpy(f['HISTORY'][:]).float()
            self.fut = torch.from_numpy(f['FUTURE'][:]).float()
            self.pos = torch.from_numpy(f['POS'][:]).float()
            self.valid_len = torch.from_numpy(f['VALID_LEN'][:]).long()
            self.norm_center = torch.from_numpy(f['NORM_CENTER'][:]).float()
            self.theta = torch.from_numpy(f['THETA'][:]).float()
            
            lane_ids = f['LANE_ID'][:]
            city_names_raw = f['CITY_NAME'][:]
            city_names = [c.decode('utf-8') if isinstance(c, bytes) else str(c) for c in city_names_raw]
            
        print(f"[{data_path}] ì°¨ì„ (Lane) í”¼ì²˜ ì‚¬ì „ ë³‘í•© ì¤‘...")
        max_lanes = lane_ids.shape[1]
        lane_tensor_np = np.zeros((self.length, max_lanes, 10, 5), dtype=np.float32)
        
        # tqdmìœ¼ë¡œ ì§„í–‰ë¥  í‘œì‹œ
        for i in tqdm(range(self.length), desc="Assembling Lanes"):
            city_map = self.map_data[city_names[i]]
            for j, l_id in enumerate(lane_ids[i]):
                if l_id != -1:
                    lane_tensor_np[i, j] = city_map[l_id]
                    
        self.lanes = torch.from_numpy(lane_tensor_np).float()
        print(f"[{data_path}] ëª¨ë“  ë°ì´í„° PyTorch Tensor ì ì¬ ì™„ë£Œ!\n")

    def __len__(self):
        return self.length

    def __getitem__(self, idx):
        return {
            'HISTORY': self.hist[idx],
            'FUTURE': self.fut[idx],
            'POS': self.pos[idx],
            'LANE': self.lanes[idx],
            'VALID_LEN': self.valid_len[idx],
            'NORM_CENTER': self.norm_center[idx],
            'THETA': self.theta[idx]
        }

# ==============================================================================
# 2. Metric ê³„ì‚° í•¨ìˆ˜ë“¤
# ==============================================================================
def compute_metrics_detailed(pred_trajs, gt_trajs, fps=5):
    """
    pred_trajs : [B, K, T, 2]
    gt_trajs   : [B, T, 2]
    fps        : sampling rate (í˜„ì¬ 5Hz)

    Returns:
        minADE, minFDE,
        RMSE (ì „ì²´ í‰ê· ),
        RMSE@1s ... RMSE@5s (ì •í™•í•œ ì‹œì  ê¸°ë°˜)
    """

    B, K, T, _ = pred_trajs.shape

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Best-of-K selection (minFDE ê¸°ì¤€)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    pred_endpoints = pred_trajs[:, :, -1, :]
    gt_endpoints   = gt_trajs[:, -1, :].unsqueeze(1)
    dist_endpoint  = torch.norm(pred_endpoints - gt_endpoints, dim=-1)
    best_idx       = torch.argmin(dist_endpoint, dim=-1)
    best_traj      = pred_trajs[torch.arange(B), best_idx]  # [B, T, 2]

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # minADE / minFDE
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    dist_all  = torch.norm(pred_trajs - gt_trajs.unsqueeze(1), dim=-1)
    ade_per_k = dist_all.mean(dim=-1)
    min_ade   = ade_per_k.min(dim=-1).values
    min_fde   = dist_endpoint.min(dim=-1).values

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # RMSE (ì „ì²´ êµ¬ê°„ í‰ê· )
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    sq_err = torch.pow(best_traj - gt_trajs, 2).sum(dim=-1)  # [B, T]
    rmse_overall = torch.sqrt(sq_err.mean(dim=-1))  # [B]

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë…¼ë¬¸ ìŠ¤íƒ€ì¼ RMSE@Ns (ì •í™•í•œ ì‹œì  ê¸°ë°˜)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    rmse_at = {}

    for s in range(1, 6):  # 1ì´ˆ ~ 5ì´ˆ
        step_idx = int(s * fps) - 1  # index ë³´ì •
        step_idx = min(step_idx, T - 1)

        rmse_s = torch.sqrt(sq_err[:, step_idx])
        rmse_at[f'RMSE@{s}s'] = rmse_s

    return {
        'minADE'     : min_ade,
        'minFDE'     : min_fde,
        'RMSE'       : rmse_overall,
        **rmse_at,
    }


# ==============================================================================
# 3. ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ í—¬í¼
# ==============================================================================
def load_checkpoint(ckpt_path, model, device):
    print(f"ğŸ“‚ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {ckpt_path}")
    ckpt = torch.load(ckpt_path, map_location=device)

    # save_checkpoint í¬ë§·ì— ë”°ë¼ í‚¤ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìœ ì—°í•˜ê²Œ ì²˜ë¦¬
    if 'state_dict' in ckpt:
        state = ckpt['state_dict']
    elif 'model_state_dict' in ckpt:
        state = ckpt['model_state_dict']
    elif 'model' in ckpt:
        state = ckpt['model']
    else:
        state = ckpt  # í†µì§¸ë¡œ state_dictì¸ ê²½ìš°

    model.load_state_dict(state, strict=True)
    saved_metric = ckpt.get('MR', ckpt.get('rmse', None))
    if saved_metric is not None:
        print(f"   â””â”€ ì €ì¥ëœ Best RMSE: {saved_metric:.4f}")
    return model


# ==============================================================================
# 4. CSV ì €ì¥ í—¬í¼
# ==============================================================================
def save_csv(result_dict, save_path):
    fieldnames = list(result_dict.keys())
    with open(save_path, 'w', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerow(result_dict)
    print(f"ğŸ“„ ê²°ê³¼ CSV ì €ì¥ ì™„ë£Œ: {save_path}")


# ==============================================================================
# 3. Inference Time Measurement Function
# ==============================================================================
def measure_inference_time(model, dataset, device, num_iters=10000):
    """
    Batch Size 1ë¡œ num_itersë§Œí¼ ì¶”ë¡  ì‹œê°„ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
    """
    model.eval()
    # Batch size 1ë¡œ í•˜ë‚˜ì˜ ìƒ˜í”Œ ì¶”ì¶œ
    sample = dataset[0]
    batch_data = {}
    for k, v in sample.items():
        if isinstance(v, torch.Tensor):
            batch_data[k] = v.unsqueeze(0).to(device)

    latencies = []
    print(f"\nâ±ï¸ Inference Time ì¸¡ì • ì‹œì‘ (Iterations: {num_iters}, Batch Size: 1)")
    
    with torch.no_grad():
        # Warm-up (100 iters)
        for _ in range(100):
            with autocast(device_type='cuda' if device.type == 'cuda' else 'cpu'):
                _ = model(batch_data)
        
        # ì‹¤ì œ ì¸¡ì •
        for _ in tqdm(range(num_iters), desc="Measuring Latency"):
            if device.type == 'cuda':
                torch.cuda.synchronize()
            
            start_time = time.perf_counter()
            
            with autocast(device_type='cuda' if device.type == 'cuda' else 'cpu'):
                _ = model(batch_data)
            
            if device.type == 'cuda':
                torch.cuda.synchronize()
            
            end_time = time.perf_counter()
            latencies.append((end_time - start_time) * 1000) # ms ë‹¨ìœ„ ì €ì¥

    latencies = np.array(latencies)
    avg_t = np.mean(latencies)
    min_t = np.min(latencies)
    max_t = np.max(latencies)
    std_t = np.std(latencies)

    print(f"\n" + "="*50)
    print(f" ğŸ Inference Time ê²°ê³¼ (Batch Size: 1)")
    print(f"  - Average : {avg_t:.4f} ms")
    print(f"  - Minimum : {min_t:.4f} ms")
    print(f"  - Maximum : {max_t:.4f} ms")
    print(f"  - Std Dev : {std_t:.4f} ms")
    print("="*50 + "\n")
    
    return {'avg': avg_t, 'min': min_t, 'max': max_t}

# ==============================================================================
# 5. í‰ê°€ ë©”ì¸ í•¨ìˆ˜
# ==============================================================================
def evaluate(args):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    cfg = load_config_data(args.config)

    # âœ… ì‹¤í—˜ ëª¨ë“œ ë° ì±„ë„ ìë™ ì„¤ì • (train.pyì™€ ë™ê¸°í™”)
    feature_mode = cfg.get('exp', {}).get('feature_mode', 'baseline')
    num_extra = len(EXTRA_FEATURE_MAP[feature_mode])
    in_channels = 4 + num_extra
    
    model_cfg = cfg.get('model', {})
    model_cfg['in_channels'] = in_channels
    model_cfg['max_lane_num'], model_cfg['max_agent_num'] = 6, 9
    model_cfg['lane_channels'] = 7
    model_cfg['out_channels'] = model_cfg.get('future_num_frames', 25) * 2

    model = mmTrans(STF, model_cfg).to(device)

    # âœ… ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ìë™ íƒìƒ‰
    if args.ckpt:
        ckpt_path = args.ckpt
    else:
        ckpt_dir = Path(cfg.get('train', {}).get('ckpt_dir', './ckpts'))
        ckpt_path = ckpt_dir / feature_mode / "best.pt"

    print(f"ğŸ“‚ í‰ê°€ ëª¨ë¸: {ckpt_path} (Mode: {feature_mode})")
    checkpoint = torch.load(ckpt_path, map_location=device)
    model.load_state_dict(checkpoint.get('model_state_dict', checkpoint.get('state_dict', checkpoint)))
    model.eval()

    # âœ… ë°ì´í„° ê²½ë¡œ ìë™ ì„¤ì •
    data_dir = Path(args.data_dir) / feature_mode
    dataset = HighDDataset(str(data_dir / f"{args.split}.h5"), str(data_dir / "map.pkl"))
    loader = DataLoader(dataset, batch_size=cfg.get('data', {}).get('batch_size', 512), 
                        shuffle=False, num_workers=8, pin_memory=True)

    # --- Mode 1: Inference Time Measurement ---
    if args.measure_time:
        measure_inference_time(model, dataset, device, num_iters=10000)
        return

    metric_keys = ['minADE', 'minFDE', 'RMSE'] + [f'RMSE@{s}s' for s in range(1, 6)]
    accum = {k: 0.0 for k in metric_keys}
    total_samples = 0

    with torch.no_grad():
        pbar = tqdm(loader, desc=f"Eval [{args.split}]")
        for batch_data in pbar:
            for k, v in batch_data.items():
                if isinstance(v, torch.Tensor): batch_data[k] = v.to(device)

            with autocast(device_type='cuda'):
                pred, _ = model(batch_data)
            
            target_pred = pred[:, 0, ...] if pred.dim() == 5 else pred
            target_gt = batch_data['FUTURE'][:, 0, :, :2]
            
            metrics = compute_metrics_detailed(target_pred, target_gt)
            for k in metric_keys: accum[k] += metrics[k].sum().item()
            total_samples += target_gt.size(0)

    final = {k: accum[k] / total_samples for k in metric_keys}
    
    header = f" ğŸ Final Evaluation Result: [{feature_mode}] "
    print("\n" + " " * 10 + "â—" * 40)
    print(f"{header:^60}")
    print(" " * 10 + "â—" * 40 + "\n")

    # 1. í•µì‹¬ ì§€í‘œ (Overall Metrics)
    print(f"  ğŸ“‚ Target Split  : {args.split}")
    print(f"  ğŸ”¢ Total Samples : {total_samples:,}")
    print(f"  ğŸ“ Checkpoint    : {Path(ckpt_path).name}")
    print("-" * 50)
    
    print(f"  ğŸ”¥ minADE        : {final['minADE']:.4f} m")
    print(f"  ğŸ”¥ minFDE        : {final['minFDE']:.4f} m")
    print(f"  ğŸ”¥ RMSE (Total)  : {final['RMSE']:.4f} m")
    
    print("-" * 50)
    
    # 2. ì‹œê°„ëŒ€ë³„ ìƒì„¸ ì§€í‘œ (Time-step Metrics)
    # ë…¼ë¬¸ì— ë“¤ì–´ê°ˆ RMSE@Ns ìˆ˜ì¹˜ë¥¼ í…Œì´ë¸” í˜•íƒœë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
    print(f"  ğŸ•’ Time-step Analysis (RMSE)")
    print(f"  {'-' * 32}")
    print(f"  |  1.0s  |  2.0s  |  3.0s  |  4.0s  |  5.0s  |")
    print(f"  | {final['RMSE@1s']:^6.3f} | {final['RMSE@2s']:^6.3f} | {final['RMSE@3s']:^6.3f} | {final['RMSE@4s']:^6.3f} | {final['RMSE@5s']:^6.3f} |")
    print(f"  {'-' * 32}")

    print("\n" + "=" * 50 + "\n")

    if args.save_csv:
        os.makedirs(args.output_dir, exist_ok=True)
        csv_path = os.path.join(args.output_dir, f"eval_{feature_mode}_{args.split}.csv")
        with open(csv_path, 'w', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=['mode'] + metric_keys)
            writer.writeheader()
            writer.writerow({'mode': feature_mode, **final})
        print(f"ğŸ“„ CSV Saved: {csv_path}")

    return final


# ==============================================================================
# 6. Entry Point
# ==============================================================================
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', type=str, default='configs/baseline.yaml')
    parser.add_argument('--data_dir', type=str, default='highD')
    parser.add_argument('--split', type=str, default='test', choices=['val', 'test'])
    parser.add_argument('--ckpt', type=str, default=None)
    parser.add_argument('--measure_time', action='store_true')
    parser.add_argument('--save_csv', action='store_true', default=True)
    parser.add_argument('--output_dir', type=str, default='./results')
    
    evaluate(args := parser.parse_args())